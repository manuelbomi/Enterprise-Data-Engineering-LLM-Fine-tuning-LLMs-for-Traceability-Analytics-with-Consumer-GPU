{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28a8dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Engineering LLM Fine-Tuning Setup\n",
      " 2026-01-23 07:41:50\n",
      " Working Directory: /home/manuelbomi/fine_tune_LLM\n",
      " PyTorch Version: 2.9.1+cu128\n",
      " CUDA Available: True\n",
      " GPU: NVIDIA GeForce RTX 4070 Laptop GPU (8.6 GB VRAM)\n",
      " CUDA Capability: (8, 9)\n",
      " GPU memory cleared\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Environment check & imports for Data Engineering LLM\n",
    "# OVERVIEW: Sets up environment for data engineering LLM fine-tuning with Gemma 2B\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any, List\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "print(f\" Data Engineering LLM Fine-Tuning Setup\")\n",
    "print(f\" {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\" Working Directory: {os.getcwd()}\")\n",
    "print(f\" PyTorch Version: {torch.__version__}\")\n",
    "print(f\" CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\" GPU: {gpu_name} ({gpu_memory:.1f} GB VRAM)\")\n",
    "    print(f\" CUDA Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "else:\n",
    "    print(\" No GPU detected - training will be very slow!\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f\" GPU memory cleared\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42332a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 2000 examples from enhanced_data_engineering_dataset.json\n",
      "\n",
      " Total training examples: 2000\n",
      " Sample task type: ['task_type', 'input', 'output']\n"
     ]
    }
   ],
   "source": [
    "## Load data engineering training data\n",
    "# OVERVIEW: Loads specialized data engineering training examples\n",
    "\n",
    "data_files = [\n",
    "    \"enhanced_data_engineering_dataset.json\"    \n",
    "]\n",
    "\n",
    "all_data = []\n",
    "for data_file in data_files:\n",
    "    if os.path.exists(data_file):\n",
    "        with open(data_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "            print(f\" Loaded {len(data)} examples from {data_file}\")\n",
    "    else:\n",
    "        print(f\"  File not found: {data_file}\")\n",
    "\n",
    "print(f\"\\n Total training examples: {len(all_data)}\")\n",
    "if len(all_data) > 0:\n",
    "    print(f\" Sample task type: {list(all_data[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b3ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Available Models for Data Engineering Tasks:\n",
      "  1. gemma                â†’ unsloth/gemma-2b-bnb-4bit\n",
      "  2. llama                â†’ unsloth/llama-3.2-3b-bnb-4bit\n",
      "  3. deepseek             â†’ unsloth/deepseek-coder-1.3b-bnb-4bit\n",
      "  4. tinyllama            â†’ unsloth/tinyllama-bnb-4bit\n",
      "  5. Phi                  â†’ unsloth/Phi-3-mini-4k-instruct-bnb-4bit\n",
      "\n",
      " Selected Model: unsloth/gemma-2b-bnb-4bit\n",
      " Reason: Gemma 2B offers excellent balance of efficiency and capability for structured data tasks\n"
     ]
    }
   ],
   "source": [
    "### Model Selection for Data Engineering\n",
    "# OVERVIEW: Selects Gemma 2B for data engineering tasks\n",
    "\n",
    "# Available models optimized for data engineering tasks\n",
    "available_models = [\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",            # 2B - Google's efficient model (RECOMMENDED)\n",
    "    \"unsloth/llama-3.2-3b-bnb-4bit\",        # 3B - Meta's latest small model\n",
    "    \"unsloth/deepseek-coder-1.3b-bnb-4bit\", # 1.3B - Code specialized\n",
    "    \"unsloth/tinyllama-bnb-4bit\",           # 1.1B - Smallest & fastest\n",
    "    \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\", # 3.8B - Instruction tuned\n",
    "]\n",
    "\n",
    "print(\" Available Models for Data Engineering Tasks:\")\n",
    "for i, model in enumerate(available_models, 1):\n",
    "    size = model.split('-')[0].split('/')[-1]\n",
    "    print(f\"  {i}. {size:<20} â†’ {model}\")\n",
    "\n",
    "# Select Gemma 2B for data engineering\n",
    "MODEL_CHOICE = \"gemma-2b\"  # Changed to Gemma 2B\n",
    "\n",
    "model_map = {\n",
    "    \"gemma-2b\": \"unsloth/gemma-2b-bnb-4bit\",\n",
    "    \"llama3.2-3b\": \"unsloth/llama-3.2-3b-bnb-4bit\",\n",
    "    \"deepseek-coder\": \"unsloth/deepseek-coder-1.3b-bnb-4bit\",\n",
    "    \"tinyllama\": \"unsloth/tinyllama-bnb-4bit\",\n",
    "    \"phi-3-mini\": \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n",
    "}\n",
    "\n",
    "model_name = model_map[MODEL_CHOICE]\n",
    "print(f\"\\n Selected Model: {model_name}\")\n",
    "print(f\" Reason: Gemma 2B offers excellent balance of efficiency and capability for structured data tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c80725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      " Loading unsloth/gemma-2b-bnb-4bit with max_seq_length=2048...\n",
      "==((====))==  Unsloth 2026.1.3: Fast Gemma patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      " Loaded: unsloth/gemma-2b-bnb-4bit\n",
      " Model Parameters: 1,515,268,096\n",
      " Tokenizer Vocab Size: 256000\n",
      " Max Position Embeddings: 8192\n",
      "  Model Config:\n",
      "  - Architecture: GemmaForCausalLM\n",
      "  - Hidden Size: 2048\n",
      "  - Num Attention Heads: 8\n",
      "  - Num Hidden Layers: 18\n"
     ]
    }
   ],
   "source": [
    "### Load Gemma 2B model and tokenizer\n",
    "# OVERVIEW: Loads Gemma 2B with optimized settings for data engineering tasks\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Gemma uses different chat template - longer context for data engineering\n",
    "max_seq_length = 2048  # Increased for data engineering tasks\n",
    "print(f\" Loading {model_name} with max_seq_length={max_seq_length}...\")\n",
    "\n",
    "# Load with optimized settings for Gemma\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=None,  # Auto-detect\n",
    "    load_in_4bit=True,\n",
    "    token=os.getenv(\"HF_TOKEN\", None),  # Optional: for gated models\n",
    ")\n",
    "\n",
    "# Gemma specific tokenizer setup\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Print model info\n",
    "print(f\" Loaded: {model_name}\")\n",
    "print(f\" Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\" Tokenizer Vocab Size: {tokenizer.vocab_size}\")\n",
    "print(f\" Max Position Embeddings: {model.config.max_position_embeddings}\")\n",
    "\n",
    "# Gemma specific settings\n",
    "print(f\"  Model Config:\")\n",
    "print(f\"  - Architecture: {model.config.architectures[0]}\")\n",
    "print(f\"  - Hidden Size: {model.config.hidden_size}\")\n",
    "print(f\"  - Num Attention Heads: {model.config.num_attention_heads}\")\n",
    "print(f\"  - Num Hidden Layers: {model.config.num_hidden_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de80a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Preparing Data Engineering Training Data...\n",
      " Dataset Statistics:\n",
      "  - Total Examples: 2000\n",
      "  - Training Set: 1600\n",
      "  - Validation Set: 400\n",
      "  - Task Distribution:\n",
      "      â€¢ schema_inference: 400 examples (20.0%)\n",
      "      â€¢ sql_optimization: 400 examples (20.0%)\n",
      "      â€¢ etl_pipeline: 400 examples (20.0%)\n",
      "      â€¢ extraction: 400 examples (20.0%)\n",
      "      â€¢ data_quality: 400 examples (20.0%)\n",
      "\n",
      " Adding LoRA Adapters for Gemma 2B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.3 patched 18 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LoRA Configuration Complete:\n",
      "   Trainable Parameters: 39,223,296\n",
      "   Total Parameters: 1,554,491,392\n",
      "   Trainable %: 2.523%\n",
      "   Memory per Parameter: ~0.8 GB (4-bit quantized)\n"
     ]
    }
   ],
   "source": [
    "## Prepare data engineering training data\n",
    "# OVERVIEW: Formats data engineering examples using Gemma's chat template\n",
    "\n",
    "from datasets import Dataset\n",
    "import random\n",
    "\n",
    "print(\"\\n  Preparing Data Engineering Training Data...\")\n",
    "\n",
    "def format_data_engineering_example(example):\n",
    "    \"\"\"Format examples for Gemma 2B with data engineering focus\"\"\"\n",
    "    \n",
    "    # Gemma chat format\n",
    "    template = \"\"\"<start_of_turn>user\n",
    "{system_prompt}\n",
    "\n",
    "{user_prompt}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "{assistant_response}<end_of_turn>\"\"\"\n",
    "    \n",
    "    # Determine task type and format accordingly\n",
    "    task_type = example.get('task_type', 'extraction')\n",
    "    \n",
    "    if task_type == 'schema_inference':\n",
    "        system_prompt = \"You are a data engineer. Infer database schema from the given data description.\"\n",
    "        user_prompt = example['input']\n",
    "        assistant_response = json.dumps(example['output'], indent=2)\n",
    "    \n",
    "    elif task_type == 'data_quality':\n",
    "        system_prompt = \"You are a data quality engineer. Generate data quality rules for the given table description.\"\n",
    "        user_prompt = example['input']\n",
    "        assistant_response = json.dumps(example['output'], indent=2)\n",
    "    \n",
    "    elif task_type == 'etl_pipeline':\n",
    "        system_prompt = \"You are an ETL pipeline architect. Design a data pipeline from the given requirements.\"\n",
    "        user_prompt = example['input']\n",
    "        assistant_response = json.dumps(example['output'], indent=2)\n",
    "    \n",
    "    elif task_type == 'sql_optimization':\n",
    "        system_prompt = \"You are a database performance expert. Optimize the given SQL query.\"\n",
    "        user_prompt = example['input']\n",
    "        assistant_response = json.dumps(example['output'], indent=2)\n",
    "    \n",
    "    else:  # Default extraction task\n",
    "        system_prompt = \"Extract structured JSON data from the given text.\"\n",
    "        user_prompt = example['input']\n",
    "        assistant_response = json.dumps(example['output'], indent=2)\n",
    "    \n",
    "    return template.format(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    )\n",
    "\n",
    "# Format all examples\n",
    "formatted_data = [format_data_engineering_example(item) for item in all_data]\n",
    "\n",
    "# Split into train/validation (80/20)\n",
    "random.shuffle(formatted_data)\n",
    "split_idx = int(0.8 * len(formatted_data))\n",
    "train_data = formatted_data[:split_idx]\n",
    "val_data = formatted_data[split_idx:]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\"text\": train_data})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_data})\n",
    "\n",
    "print(f\" Dataset Statistics:\")\n",
    "print(f\"  - Total Examples: {len(formatted_data)}\")\n",
    "print(f\"  - Training Set: {len(train_data)}\")\n",
    "print(f\"  - Validation Set: {len(val_data)}\")\n",
    "print(f\"  - Task Distribution:\")\n",
    "task_types = [item.get('task_type', 'extraction') for item in all_data]\n",
    "for task in set(task_types):\n",
    "    count = task_types.count(task)\n",
    "    print(f\"      â€¢ {task}: {count} examples ({(count/len(all_data))*100:.1f}%)\")\n",
    "\n",
    "# Add LoRA with optimized settings for Gemma\n",
    "print(\"\\n Adding LoRA Adapters for Gemma 2B...\")\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,  # Rank - good balance for Gemma\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,  # Slight dropout for regularization\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\" LoRA Configuration Complete:\")\n",
    "print(f\"   Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "print(f\"   Trainable %: {(trainable_params/total_params)*100:.3f}%\")\n",
    "print(f\"   Memory per Parameter: ~{(total_params * 0.5) / 1e9:.1f} GB (4-bit quantized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36da993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ“ Configuring Simplified Training Pipeline...\n",
      " Preparing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5a08027f5a4308a7fb9a11ec9b4489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cb546e64c148b1b7a0ea65493a744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,600 | Num Epochs = 3 | Total steps = 600\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 39,223,296 of 2,545,395,712 (1.54% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting training...\n",
      "   Model: gemma-2b\n",
      "   Training samples: 1600\n",
      "   Sequence length: 2048\n",
      "   Estimated time: 15-30 minutes\n",
      "\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 1:46:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.496800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.207200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.116100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.152400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.119700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.121400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.123600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.080600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.111900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.083300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.106900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.125700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.103400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.143600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.171800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.073200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.085600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.112300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.137300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.110200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.101900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.110300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.131700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.121200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>0.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>0.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555</td>\n",
       "      <td>0.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b126cc76-41d4-4598-836f-6e5e6f3146f5)')' thrown while requesting HEAD https://huggingface.co/unsloth/gemma-2b-bnb-4bit/resolve/main/config.json\n",
      "[huggingface_hub.utils._http|WARNING]'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b126cc76-41d4-4598-836f-6e5e6f3146f5)')' thrown while requesting HEAD https://huggingface.co/unsloth/gemma-2b-bnb-4bit/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "[huggingface_hub.utils._http|WARNING]Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Complete!\n",
      " Model saved to: gemma-2b-finetuned-simple\n",
      " Final loss: 0.1881\n"
     ]
    }
   ],
   "source": [
    "## Simplified Training Pipeline\n",
    "# OVERVIEW: Basic training without SFTTrainer complexities\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nðŸŽ“ Configuring Simplified Training Pipeline...\")\n",
    "\n",
    "# Simple batch size\n",
    "batch_size = 2\n",
    "gradient_accumulation = 4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"simple-outputs-{MODEL_CHOICE}\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation,\n",
    "    warmup_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=5,\n",
    "    save_steps=60,\n",
    "    save_total_limit=2,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    gradient_checkpointing=False,  # Disable for simplicity\n",
    ")\n",
    "\n",
    "# Create a simple tokenization function\n",
    "def prepare_dataset(dataset):\n",
    "    \"\"\"Prepare dataset with proper tokenization\"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_seq_length,\n",
    "        )\n",
    "    \n",
    "    return dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )\n",
    "\n",
    "print(\" Preparing datasets...\")\n",
    "train_dataset_prepared = prepare_dataset(train_dataset)\n",
    "val_dataset_prepared = prepare_dataset(val_dataset)\n",
    "\n",
    "# Create data collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_prepared,\n",
    "    eval_dataset=val_dataset_prepared,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(f\"\\n Starting training...\")\n",
    "print(f\"   Model: {MODEL_CHOICE}\")\n",
    "print(f\"   Training samples: {len(train_dataset_prepared)}\")\n",
    "print(f\"   Sequence length: {max_seq_length}\")\n",
    "print(f\"   Estimated time: 15-30 minutes\\n\")\n",
    "\n",
    "# Train\n",
    "train_history = trainer.train()\n",
    "\n",
    "# Save\n",
    "output_dir = f\"{MODEL_CHOICE}-finetuned-simple\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"\\n Training Complete!\")\n",
    "print(f\" Model saved to: {output_dir}\")\n",
    "print(f\" Final loss: {train_history.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2175b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# After training, add this to your script:\\nprint(\"\\n\" + \"=\"*100)\\nprint(\"RUNNING COMPREHENSIVE TEST SUITE\")\\nprint(\"=\"*100)\\n\\n# Prepare model for inference\\nmodel = prepare_model_for_inference(model)\\n\\n# Run comprehensive tests\\ntest_results = run_comprehensive_test_suite(model, tokenizer, max_seq_length)\\n\\nprint(\"Testing complete! Model is ready for deployment.\" if test_results[\"success_rate\"] > 70 else \\n      \"Model needs improvement before deployment.\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Enhanced Data Engineering Model Testing Suite\n",
    "# OVERVIEW: Comprehensive testing for all data engineering task types\n",
    "\n",
    "\n",
    "\n",
    "def prepare_model_for_inference(model):\n",
    "    \"\"\"Prepare model for inference mode\"\"\"\n",
    "    from unsloth import FastLanguageModel\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    return model\n",
    "\n",
    "def test_data_engineering_model(model, tokenizer, test_input: str, task_type: str = \"extraction\", \n",
    "                                max_seq_length: int = 2048) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Test the fine-tuned model on data engineering tasks\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned model\n",
    "        tokenizer: Model tokenizer\n",
    "        test_input: Input text to test\n",
    "        task_type: Type of data engineering task\n",
    "        max_seq_length: Maximum sequence length\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing response and validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    # System prompts for different tasks - MUST match training prompts\n",
    "    system_prompts = {\n",
    "        \"extraction\": \"Extract structured JSON data from the given text.\",\n",
    "        \"schema_inference\": \"You are a data engineer. Infer database schema from the given data description.\",\n",
    "        \"data_quality\": \"You are a data quality engineer. Generate data quality rules for the given table description.\",\n",
    "        \"etl_pipeline\": \"You are an ETL pipeline architect. Design a data pipeline from the given requirements.\",\n",
    "        \"sql_optimization\": \"You are a database performance expert. Optimize the given SQL query.\"\n",
    "    }\n",
    "    \n",
    "    system_prompt = system_prompts.get(task_type, system_prompts[\"extraction\"])\n",
    "    \n",
    "    # Use EXACT same format as training\n",
    "    # Training format: <start_of_turn>user\\n{system_prompt}\\n\\n{user_prompt}<end_of_turn>\\n<start_of_turn>model\\n{assistant_response}<end_of_turn>\n",
    "    # For testing: we give the prompt up to where model should start generating\n",
    "    formatted_prompt = f\"\"\"<start_of_turn>user\n",
    "{system_prompt}\n",
    "\n",
    "{test_input}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        [formatted_prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Generation parameters optimized for structured output\n",
    "    generation_config = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 40,\n",
    "        \"do_sample\": False,  # Deterministic for structured data\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generation_config)\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract model response\n",
    "    if \"<start_of_turn>model\" in full_response:\n",
    "        response = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        response = response.replace(\"<end_of_turn>\", \"\").strip()\n",
    "    else:\n",
    "        response = full_response\n",
    "    \n",
    "    # Validate response based on task type\n",
    "    validation_result = validate_response(response, task_type)\n",
    "    \n",
    "    return {\n",
    "        \"task_type\": task_type,\n",
    "        \"input\": test_input,\n",
    "        \"response\": response,\n",
    "        \"validation\": validation_result,\n",
    "        \"formatted_prompt\": formatted_prompt[:200] + \"...\" if len(formatted_prompt) > 200 else formatted_prompt\n",
    "    }\n",
    "\n",
    "def validate_response(response: str, task_type: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate model response based on task type\n",
    "    \n",
    "    Args:\n",
    "        response: Model response text\n",
    "        task_type: Type of task\n",
    "    \n",
    "    Returns:\n",
    "        Validation results dictionary\n",
    "    \"\"\"\n",
    "    validation_result = {\n",
    "        \"is_valid_json\": False,\n",
    "        \"has_expected_structure\": False,\n",
    "        \"error_message\": None,\n",
    "        \"parsed_json\": None,\n",
    "        \"response_length\": len(response)\n",
    "    }\n",
    "    \n",
    "    # Task-specific expected keys\n",
    "    expected_keys_map = {\n",
    "        \"extraction\": [\"customer_id\", \"service_name\", \"subscription_plan\", \"monthly_price_usd\", \n",
    "                      \"device_type\", \"region\", \"usage_hours\", \"event_timestamp\"],\n",
    "        \"schema_inference\": [\"tables\", \"relationships\"],\n",
    "        \"data_quality\": [\"table_name\", \"quality_rules\"],\n",
    "        \"etl_pipeline\": [\"pipeline_name\", \"description\", \"frequency\", \"schedule\"],\n",
    "        \"sql_optimization\": [\"original_query\", \"optimized_query\", \"optimizations\"]\n",
    "    }\n",
    "    \n",
    "    # Clean response - remove markdown code blocks if present\n",
    "    clean_response = response.strip()\n",
    "    if clean_response.startswith(\"```json\"):\n",
    "        clean_response = clean_response[7:]\n",
    "    if clean_response.endswith(\"```\"):\n",
    "        clean_response = clean_response[:-3]\n",
    "    clean_response = clean_response.strip()\n",
    "    \n",
    "    # Special handling for SQL optimization (might return SQL directly)\n",
    "    if task_type == \"sql_optimization\":\n",
    "        if \"SELECT\" in clean_response.upper() or \"WHERE\" in clean_response.upper():\n",
    "            validation_result.update({\n",
    "                \"is_sql_response\": True,\n",
    "                \"has_expected_structure\": True,\n",
    "                \"notes\": \"SQL response detected (valid for optimization tasks)\"\n",
    "            })\n",
    "            return validation_result\n",
    "    \n",
    "    # Try to parse as JSON\n",
    "    try:\n",
    "        if clean_response.startswith(\"{\") or clean_response.startswith(\"[\"):\n",
    "            parsed = json.loads(clean_response)\n",
    "            validation_result[\"is_valid_json\"] = True\n",
    "            validation_result[\"parsed_json\"] = parsed\n",
    "            \n",
    "            # Check for expected structure\n",
    "            if task_type in expected_keys_map:\n",
    "                if isinstance(parsed, dict):\n",
    "                    expected_keys = expected_keys_map[task_type]\n",
    "                    # Check if any expected key is present (not necessarily all)\n",
    "                    found_keys = [key for key in expected_keys if key in parsed]\n",
    "                    if found_keys:\n",
    "                        validation_result[\"has_expected_structure\"] = True\n",
    "                        validation_result[\"found_keys\"] = found_keys\n",
    "                        validation_result[\"missing_keys\"] = [k for k in expected_keys if k not in found_keys]\n",
    "                    else:\n",
    "                        validation_result[\"error_message\"] = f\"No expected keys found. Expected any of: {expected_keys}\"\n",
    "                else:\n",
    "                    validation_result[\"error_message\"] = f\"Response is not a dictionary. Type: {type(parsed)}\"\n",
    "        else:\n",
    "            validation_result[\"error_message\"] = \"Response does not start with { or [\"\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        validation_result[\"error_message\"] = f\"JSON decode error: {str(e)}\"\n",
    "        # Try to find where JSON breaks\n",
    "        lines = clean_response.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            try:\n",
    "                json.loads(line)\n",
    "            except:\n",
    "                validation_result[\"json_error_line\"] = i + 1\n",
    "                validation_result[\"json_error_content\"] = line[:100]\n",
    "                break\n",
    "    \n",
    "    return validation_result\n",
    "\n",
    "def run_comprehensive_test_suite(model, tokenizer, max_seq_length: int = 2048):\n",
    "    \"\"\"\n",
    "    Run comprehensive test suite covering all data engineering tasks\n",
    "    \n",
    "    Args:\n",
    "        model: Fine-tuned model\n",
    "        tokenizer: Model tokenizer\n",
    "        max_seq_length: Maximum sequence length\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"COMPREHENSIVE DATA ENGINEERING LLM TEST SUITE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Comprehensive test suite covering all task types\n",
    "    test_suite = [\n",
    "        # 1. Data Extraction Tests\n",
    "        {\n",
    "            \"task\": \"Data Extraction - Basic\",\n",
    "            \"input\": \"Extract subscription usage details:\\nCustomer 10001 used Apple Music on Game Console under the Basic plan costing $16.23 in region AU.\",\n",
    "            \"type\": \"extraction\",\n",
    "            \"description\": \"Basic structured data extraction\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"Data Extraction - Multiple Services\",\n",
    "            \"input\": \"Extract subscription usage details:\\nCustomer 20045 used Netflix on Smart TV under the Premium plan costing $19.99 in region US with 8.5 hours of usage on 2024-07-15.\",\n",
    "            \"type\": \"extraction\",\n",
    "            \"description\": \"Extraction with additional details\"\n",
    "        },\n",
    "        \n",
    "        # 2. Schema Inference Tests\n",
    "        {\n",
    "            \"task\": \"Schema Inference - Streaming Service\",\n",
    "            \"input\": \"Design a database schema for tracking Disney+ subscription usage. Include customer details, subscription info, and usage metrics.\",\n",
    "            \"type\": \"schema_inference\",\n",
    "            \"description\": \"Complete database schema design\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"Schema Inference - Simple Table\",\n",
    "            \"input\": \"Infer schema from CSV with columns: 'user_id,email,signup_date,last_login,plan_type' with sample: '123,user@example.com,2024-01-15,2024-06-20,premium'\",\n",
    "            \"type\": \"schema_inference\",\n",
    "            \"description\": \"Schema inference from CSV description\"\n",
    "        },\n",
    "        \n",
    "        # 3. Data Quality Tests\n",
    "        {\n",
    "            \"task\": \"Data Quality - Subscription Data\",\n",
    "            \"input\": \"Generate data quality rules for subscription data with fields: customer_id, service_name, subscription_plan, monthly_price_usd, device_type, region, usage_hours, event_timestamp\",\n",
    "            \"type\": \"data_quality\",\n",
    "            \"description\": \"Comprehensive data quality rules\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"Data Quality - Customer Table\",\n",
    "            \"input\": \"Generate data quality rules for a customer table with columns: customer_id (int), email (string), age (int), signup_date (date)\",\n",
    "            \"type\": \"data_quality\",\n",
    "            \"description\": \"Basic table quality rules\"\n",
    "        },\n",
    "        \n",
    "        # 4. ETL Pipeline Tests\n",
    "        {\n",
    "            \"task\": \"ETL Pipeline - Netflix Daily\",\n",
    "            \"input\": \"Design an ETL pipeline to process daily Netflix subscription data from CSV files to a data warehouse for analytics.\",\n",
    "            \"type\": \"etl_pipeline\",\n",
    "            \"description\": \"Daily batch ETL pipeline\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"ETL Pipeline - Real-time Streaming\",\n",
    "            \"input\": \"Design a real-time ETL pipeline for Spotify subscription events from Kafka to analytics database.\",\n",
    "            \"type\": \"etl_pipeline\",\n",
    "            \"description\": \"Real-time streaming pipeline\"\n",
    "        },\n",
    "        \n",
    "        # 5. SQL Optimization Tests\n",
    "        {\n",
    "            \"task\": \"SQL Optimization - Date Filter\",\n",
    "            \"input\": \"Optimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND region = 'AU'\",\n",
    "            \"type\": \"sql_optimization\",\n",
    "            \"description\": \"Date function optimization\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"SQL Optimization - Aggregation\",\n",
    "            \"input\": \"Optimize this SQL query: SELECT service_name, COUNT(*) as total_subscriptions, AVG(monthly_price_usd) as avg_price FROM subscriptions GROUP BY service_name ORDER BY total_subscriptions DESC\",\n",
    "            \"type\": \"sql_optimization\",\n",
    "            \"description\": \"Aggregation query optimization\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"SQL Optimization - Join\",\n",
    "            \"input\": \"Optimize this SQL query: SELECT c.customer_id, c.email, s.service_name, s.monthly_price_usd FROM customers c JOIN subscriptions s ON c.customer_id = s.customer_id WHERE s.region = 'US' AND s.is_active = true\",\n",
    "            \"type\": \"sql_optimization\",\n",
    "            \"description\": \"Join query optimization\"\n",
    "        },\n",
    "        \n",
    "        # 6. Edge Cases\n",
    "        {\n",
    "            \"task\": \"Edge Case - Minimal Input\",\n",
    "            \"input\": \"Extract data: Customer 999 used Service X.\",\n",
    "            \"type\": \"extraction\",\n",
    "            \"description\": \"Minimal input test\"\n",
    "        },\n",
    "        {\n",
    "            \"task\": \"Edge Case - Complex SQL\",\n",
    "            \"input\": \"Optimize: SELECT * FROM (SELECT customer_id, service_name, ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY event_timestamp DESC) as rn FROM subscriptions) WHERE rn = 1\",\n",
    "            \"type\": \"sql_optimization\",\n",
    "            \"description\": \"Complex window function optimization\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Statistics\n",
    "    total_tests = len(test_suite)\n",
    "    passed_tests = 0\n",
    "    failed_tests = 0\n",
    "    \n",
    "    # Run all tests\n",
    "    for i, test_case in enumerate(test_suite, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"  TEST {i}/{total_tests}: {test_case['task']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\" Description: {test_case['description']}\")\n",
    "        print(f\" Task Type: {test_case['type']}\")\n",
    "        print(f\" Input: {test_case['input'][:120]}...\" if len(test_case['input']) > 120 else f\"ðŸ“¥ Input: {test_case['input']}\")\n",
    "        \n",
    "        try:\n",
    "            # Run test\n",
    "            result = test_data_engineering_model(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                test_input=test_case['input'],\n",
    "                task_type=test_case['type'],\n",
    "                max_seq_length=max_seq_length\n",
    "            )\n",
    "            \n",
    "            # Display response\n",
    "            print(f\"\\n Response ({len(result['response'])} chars):\")\n",
    "            print(f\"{'-'*60}\")\n",
    "            \n",
    "            # Truncate long responses\n",
    "            response_display = result['response']\n",
    "            if len(response_display) > 500:\n",
    "                response_display = response_display[:250] + \"\\n... [TRUNCATED] ...\\n\" + response_display[-250:]\n",
    "            print(response_display)\n",
    "            print(f\"{'-'*60}\")\n",
    "            \n",
    "            # Display validation results\n",
    "            validation = result['validation']\n",
    "            print(f\"\\n Validation Results:\")\n",
    "            print(f\"   âœ“ Valid JSON: {validation['is_valid_json']}\")\n",
    "            print(f\"   âœ“ Expected Structure: {validation['has_expected_structure']}\")\n",
    "            print(f\"   âœ“ Response Length: {validation['response_length']} characters\")\n",
    "            \n",
    "            if validation['is_valid_json'] and validation['parsed_json']:\n",
    "                if isinstance(validation['parsed_json'], dict):\n",
    "                    print(f\"   âœ“ Keys in response: {list(validation['parsed_json'].keys())[:10]}{'...' if len(validation['parsed_json']) > 10 else ''}\")\n",
    "            \n",
    "            if validation.get('found_keys'):\n",
    "                print(f\"   âœ“ Found expected keys: {validation['found_keys']}\")\n",
    "            \n",
    "            if validation.get('missing_keys'):\n",
    "                print(f\"     Missing keys: {validation['missing_keys']}\")\n",
    "            \n",
    "            if validation.get('is_sql_response'):\n",
    "                print(f\"    SQL response detected (valid for optimization task)\")\n",
    "            \n",
    "            if validation['error_message']:\n",
    "                print(f\"    Error: {validation['error_message']}\")\n",
    "                if validation.get('json_error_line'):\n",
    "                    print(f\"    JSON error at line {validation['json_error_line']}: {validation.get('json_error_content', 'N/A')}\")\n",
    "                failed_tests += 1\n",
    "            else:\n",
    "                if validation['is_valid_json'] or validation.get('is_sql_response') or validation['has_expected_structure']:\n",
    "                    print(f\"    TEST PASSED\")\n",
    "                    passed_tests += 1\n",
    "                else:\n",
    "                    print(f\"     TEST PARTIALLY PASSED - Check structure\")\n",
    "                    passed_tests += 0.5  # Half credit\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n TEST FAILED WITH EXCEPTION:\")\n",
    "            print(f\"   Error: {str(e)}\")\n",
    "            print(f\"   Type: {type(e).__name__}\")\n",
    "            failed_tests += 1\n",
    "        \n",
    "        # Small delay between tests\n",
    "        import time\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"TEST SUITE SUMMARY\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\" Total Tests: {total_tests}\")\n",
    "    print(f\" Passed: {passed_tests}\")\n",
    "    print(f\" Failed: {failed_tests}\")\n",
    "    print(f\" Success Rate: {(passed_tests/total_tests)*100:.1f}%\")\n",
    "    \n",
    "    # Task-specific breakdown\n",
    "    print(f\"\\n Task Type Breakdown:\")\n",
    "    task_results = {}\n",
    "    for test_case in test_suite:\n",
    "        task_type = test_case['type']\n",
    "        if task_type not in task_results:\n",
    "            task_results[task_type] = {\"total\": 0, \"passed\": 0}\n",
    "        task_results[task_type][\"total\"] += 1\n",
    "    \n",
    "    # Note: In a real implementation, you'd track actual pass/fail per task type\n",
    "    for task_type, counts in task_results.items():\n",
    "        print(f\"   {task_type:20} {counts['total']:2} tests\")\n",
    "    \n",
    "    print(f\"\\n Recommendations:\")\n",
    "    if passed_tests / total_tests > 0.7:\n",
    "        print(\"   âœ“ Model is performing well across most tasks\")\n",
    "    else:\n",
    "        print(\"     Model needs improvement. Consider:\")\n",
    "        print(\"      - More training epochs\")\n",
    "        print(\"      - Better training data balance\")\n",
    "        print(\"      - Adjusting learning rate\")\n",
    "    \n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"total_tests\": total_tests,\n",
    "        \"passed_tests\": passed_tests,\n",
    "        \"failed_tests\": failed_tests,\n",
    "        \"success_rate\": (passed_tests/total_tests)*100\n",
    "    }\n",
    "\n",
    "# How to use in your training script:\n",
    "\"\"\"\n",
    "# After training, add this to your script:\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RUNNING COMPREHENSIVE TEST SUITE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Prepare model for inference\n",
    "model = prepare_model_for_inference(model)\n",
    "\n",
    "# Run comprehensive tests\n",
    "test_results = run_comprehensive_test_suite(model, tokenizer, max_seq_length)\n",
    "\n",
    "print(\"Testing complete! Model is ready for deployment.\" if test_results[\"success_rate\"] > 70 else \n",
    "      \"Model needs improvement before deployment.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b556be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing Data Engineering Capabilities...\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¬ Test 1: Schema Inference\n",
      " Input: Infer schema from CSV with columns: 'user_id,email,signup_date,last_login,plan_t...\n",
      "\n",
      " Response:\n",
      "----------------------------------------\n",
      "user\n",
      "You are a data engineer. Infer database schema from the given data description.\n",
      "\n",
      "Infer schema from CSV with columns: 'user_id,email,signup_date,last_login,plan_type' with sample: '123,user@example.com,2024-01-15,2024-06-20,premium'\n",
      "model\n",
      "{\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"table_name\": \"users\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"name\": \"user_id\",\n",
      "          \"type\": \"VARCHAR(20)\",\n",
      "          \"primary_key\": true,\n",
      "          \"nullable\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"email\",\n",
      "        \n",
      "... (truncated)\n",
      "----------------------------------------\n",
      "  Response is not JSON format\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¬ Test 2: Data Quality Rules\n",
      " Input: Generate data quality rules for a customer table with columns: customer_id (int)...\n",
      "\n",
      " Response:\n",
      "----------------------------------------\n",
      "user\n",
      "You are a data quality engineer. Generate data quality rules for the given table description.\n",
      "\n",
      "Generate data quality rules for a customer table with columns: customer_id (int), email (string), age (int), signup_date (date)\n",
      "model\n",
      "{\n",
      "  \"table_name\": \"customers\",\n",
      "  \"quality_rules\": [\n",
      "    {\n",
      "      \"rule_id\": \"DQ001\",\n",
      "      \"rule_name\": \"customer_email_not_null\",\n",
      "      \"rule\": \"customer_email IS NOT NULL\",\n",
      "      \"severity\": \"critical\",\n",
      "      \"description\": \"Customer email must be present\"\n",
      "    },\n",
      " \n",
      "... (truncated)\n",
      "----------------------------------------\n",
      "  Response is not JSON format\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¬ Test 3: SQL Optimization\n",
      " Input: Optimize this SQL query: SELECT * FROM orders WHERE DATE(created_at) = '2024-06-...\n",
      "\n",
      " Response:\n",
      "----------------------------------------\n",
      "user\n",
      "You are a database performance expert. Optimize the given SQL query.\n",
      "\n",
      "Optimize this SQL query: SELECT * FROM orders WHERE DATE(created_at) = '2024-06-01' ORDER BY amount DESC\n",
      "model\n",
      "{\n",
      "  \"original_query\": \"SELECT * FROM orders WHERE DATE(created_at) = '2024-06-01' ORDER BY amount DESC\",\n",
      "  \"optimized_query\": \"SELECT * FROM orders WHERE created_at >= '2024-06-01' AND created_at < '2024-06-02' ORDER BY amount DESC\",\n",
      "  \"optimizations\": [\n",
      "    \"Replace DATE() function with range comparison\",\n",
      "    \"A\n",
      "... (truncated)\n",
      "----------------------------------------\n",
      "================================================================================\n",
      "\n",
      "ðŸ”¬ Test 4: Data Extraction\n",
      " Input: Extract subscription usage details:\n",
      "Customer 10001 used Apple Music on Game Cons...\n",
      "\n",
      " Response:\n",
      "----------------------------------------\n",
      "user\n",
      "Extract structured JSON data from the given text.\n",
      "\n",
      "Extract subscription usage details:\n",
      "Customer 10001 used Apple Music on Game Console under the Basic plan costing $16.23 in region AU.\n",
      "model\n",
      "{\n",
      "  \"customer_id\": \"CUST-10001\",\n",
      "  \"service_name\": \"Apple Music\",\n",
      "  \"subscription_plan\": \"Basic\",\n",
      "  \"monthly_price_usd\": 16.23,\n",
      "  \"device_type\": \"Game Console\",\n",
      "  \"region\": \"AU\",\n",
      "  \"usage_hours\": 5.98,\n",
      "  \"event_timestamp\": \"2024-07-16T10:08:33\"\n",
      "}<unused64>model Ename\n",
      "Weekly usage summary for Apple Music\n",
      "... (truncated)\n",
      "----------------------------------------\n",
      "  Response is not JSON format\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Data Engineering Model Testing Suite\n",
    "# OVERVIEW: Comprehensive testing for data engineering tasks\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def test_data_engineering_model(model, tokenizer, test_input, task_type=\"extraction\"):\n",
    "    \"\"\"Test the fine-tuned model on data engineering tasks\"\"\"\n",
    "    \n",
    "    # System prompts for different tasks\n",
    "    system_prompts = {\n",
    "        \"extraction\": \"Extract structured JSON data from the given text.\",\n",
    "        \"schema_inference\": \"You are a data engineer. Infer database schema from the given data description.\",\n",
    "        \"data_quality\": \"You are a data quality engineer. Generate data quality rules for the given table description.\",\n",
    "        \"etl_pipeline\": \"You are an ETL pipeline architect. Design a data pipeline from the given requirements.\",\n",
    "        \"sql_optimization\": \"You are a database performance expert. Optimize the given SQL query.\"\n",
    "    }\n",
    "    \n",
    "    system_prompt = system_prompts.get(task_type, system_prompts[\"extraction\"])\n",
    "    \n",
    "    # Gemma chat format\n",
    "    formatted_prompt = f\"\"\"<start_of_turn>user\n",
    "{system_prompt}\n",
    "\n",
    "{test_input}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [formatted_prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Generation parameters optimized for structured output\n",
    "    generation_config = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 40,\n",
    "        \"do_sample\": False,  # Deterministic for structured data\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generation_config)\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract model response\n",
    "    if \"<start_of_turn>model\" in full_response:\n",
    "        response = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        response = response.replace(\"<end_of_turn>\", \"\").strip()\n",
    "    else:\n",
    "        response = full_response\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"\\n Testing Data Engineering Capabilities...\")\n",
    "\n",
    "# Test cases covering different data engineering tasks\n",
    "test_suite = [\n",
    "    {\n",
    "        \"task\": \"Data Extraction\",\n",
    "        \"input\": \"Extract subscription usage details:\\nCustomer 10001 used Apple Music on Game Console under the Basic plan costing $16.23 in region AU.\",\n",
    "        \"type\": \"extraction\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Schema Inference\",\n",
    "        \"input\": \"Infer schema from CSV with columns: 'user_id,email,signup_date,last_login,plan_type' with sample: '123,user@example.com,2024-01-15,2024-06-20,premium'\",\n",
    "        \"type\": \"schema_inference\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Data Quality Rules\",\n",
    "        \"input\": \"Generate data quality rules for a customer table with columns: customer_id (int), email (string), age (int), signup_date (date)\",\n",
    "        \"type\": \"data_quality\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"4. ETL Pipeline Design\",\n",
    "        \"input\": \"Design an ETL pipeline to process daily Netflix subscription data from CSV files to a data warehouse for analytics.\",\n",
    "        \"type\": \"etl_pipeline\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"SQL Optimization\",\n",
    "        \"input\": \"Optimize this SQL query: SELECT * FROM orders WHERE DATE(created_at) = '2024-06-01' ORDER BY amount DESC\",\n",
    "        \"type\": \"sql_optimization\"\n",
    "    }  \n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "for i, test_case in enumerate(test_suite, 1):\n",
    "    print(f\"\\nðŸ”¬ Test {i}: {test_case['task']}\")\n",
    "    print(f\" Input: {test_case['input'][:80]}...\")\n",
    "    \n",
    "    response = test_data_engineering_model(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        test_case['input'],\n",
    "        test_case['type']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n Response:\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    print(response[:500])\n",
    "    if len(response) > 500:\n",
    "        print(\"... (truncated)\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    \n",
    "    # Validate JSON if applicable\n",
    "    if test_case['type'] in ['extraction', 'schema_inference', 'data_quality']:\n",
    "        try:\n",
    "            # Try to parse as JSON\n",
    "            if response.strip().startswith(\"{\") or response.strip().startswith(\"[\"):\n",
    "                parsed = json.loads(response)\n",
    "                print(f\" Valid JSON with {len(str(parsed))} characters\")\n",
    "            else:\n",
    "                print(\"  Response is not JSON format\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\" Invalid JSON format\")\n",
    "    \n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0265c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE DATA ENGINEERING LLM TESTING\n",
      "Testing all 5 task types sequentially\n",
      "================================================================================\n",
      "\n",
      " STARTING TESTS...\n",
      "================================================================================\n",
      "\n",
      " TEST 1: 1. Data Extraction\n",
      " Task Type: extraction\n",
      " Input: Extract subscription usage details:\n",
      "Customer 10001 used Apple Music on Game Console under the Basic ...\n",
      "------------------------------------------------------------\n",
      " Response (2423 characters):\n",
      "----------------------------------------\n",
      "user\n",
      "Extract structured JSON data from the given text.\n",
      "\n",
      "Extract subscription usage details:\n",
      "Customer 10001 used Apple Music on Game Console under the Basic plan costing $16.23 in region AU.\n",
      "model\n",
      "{\n",
      "  \"customer_id\": \"CUST-10001\",\n",
      "  \"service_name\": \"Apple Music\",\n",
      "  \"subscription_plan\": \"Basic\",\n",
      "  \"monthly_price_usd\": 16.23,\n",
      "  \"device_type\": \"Game Console\",\n",
      "  \"region\": \"AU\",\n",
      "  \"usage_hours\": 5.98,\n",
      "  \n",
      "... [TRUNCATED - MIDDLE REMOVED] ...\n",
      "\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\n",
      "----------------------------------------\n",
      "\n",
      " Validation:\n",
      "    Response is not JSON format (doesn't start with { or [)\n",
      "   Response length: 2423 characters\n",
      "\n",
      "================================================================================\n",
      "\n",
      " TEST 2: 2. Schema Inference\n",
      " Task Type: schema_inference\n",
      " Input: Design a database schema for tracking Netflix subscription usage. Include customer details, subscrip...\n",
      "------------------------------------------------------------\n",
      " Response (1986 characters):\n",
      "----------------------------------------\n",
      "user\n",
      "You are a data engineer. Infer database schema from the given data description.\n",
      "\n",
      "Design a database schema for tracking Netflix subscription usage. Include customer details, subscription info, and usage metrics.\n",
      "model\n",
      "{\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"table_name\": \"customers\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"name\": \"customer_id\",\n",
      "          \"type\": \"VARCHAR(20)\",\n",
      "          \"primary_key\": tru\n",
      "... [TRUNCATED - MIDDLE REMOVED] ...\n",
      ",\n",
      "          \"nullable\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"monthly_price_usd\",\n",
      "          \"type\": \"DECIMAL(10,2)\",\n",
      "          \"nullable\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"start_date\",\n",
      "          \"type\": \"DATE\",\n",
      "          \"nullable\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"end_date\",\n",
      "          \"type\": \"DATE\",\n",
      "          \"nullable\": true\n",
      "        },\n",
      "        {\n",
      "          \"name\n",
      "----------------------------------------\n",
      "\n",
      " Validation:\n",
      "    Response is not JSON format (doesn't start with { or [)\n",
      "   Response length: 1986 characters\n",
      "\n",
      "================================================================================\n",
      "\n",
      " TEST 3: 3. Data Quality Rules\n",
      " Task Type: data_quality\n",
      " Input: Generate data quality rules for subscription data with fields: customer_id, service_name, subscripti...\n",
      "------------------------------------------------------------\n",
      " Response (1979 characters):\n",
      "----------------------------------------\n",
      "user\n",
      "You are a data quality engineer. Generate data quality rules for the given table description.\n",
      "\n",
      "Generate data quality rules for subscription data with fields: customer_id, service_name, subscription_plan, monthly_price_usd, device_type, region, usage_hours, event_timestamp\n",
      "model\n",
      "{\n",
      "  \"table_name\": \"subscriptions\",\n",
      "  \"quality_rules\": [\n",
      "    {\n",
      "      \"rule_id\": \"DQ101\",\n",
      "      \"rule_name\": \"price_pl\n",
      "... [TRUNCATED - MIDDLE REMOVED] ...\n",
      "t be Reasonable DÃ©tails+\": \" utilisons \"AWS Data Quality Tools dicendo jbl Ã‚ge MalgrÃ©+\": \"siÄ…Å¼ka mÃ©diÃ© Ã‚ge Jusqu+\": mÃ©diÃ© DerniÃ¨re Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ© Jusqu+\": mÃ©diÃ©\n",
      "----------------------------------------\n",
      "\n",
      " Validation:\n",
      "    Response is not JSON format (doesn't start with { or [)\n",
      "   Response length: 1979 characters\n",
      "\n",
      "================================================================================\n",
      "\n",
      " TEST 4: 4. ETL Pipeline Design\n",
      " Task Type: etl_pipeline\n",
      " Input: Design an ETL pipeline to process daily Netflix subscription data from CSV files to a data warehouse...\n",
      "------------------------------------------------------------\n",
      " Response (2588 characters):\n",
      "----------------------------------------\n",
      "user\n",
      "You are an ETL pipeline architect. Design a data pipeline from the given requirements.\n",
      "\n",
      "Design an ETL pipeline to process daily Netflix subscription data from CSV files to a data warehouse for analytics.\n",
      "model\n",
      "{\n",
      "  \"pipeline_name\": \"daily_netflix_etl\",\n",
      "  \"description\": \"Daily ETL pipeline for Netflix subscription data\",\n",
      "  \"frequency\": \"daily\",\n",
      "  \"schedule\": \"00:30 UTC\",\n",
      "  \"source\": \"CSV files \n",
      "... [TRUNCATED - MIDDLE REMOVED] ...\n",
      "DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\": cahier des charges DÃ©tails mÃ©diÃ© Jusqu+\":\n",
      "----------------------------------------\n",
      "\n",
      " Validation:\n",
      "    Response is not JSON format (doesn't start with { or [)\n",
      "   Response length: 2588 characters\n",
      "\n",
      "================================================================================\n",
      "\n",
      " TEST 5: 5. SQL Optimization\n",
      " Task Type: sql_optimization\n",
      " Input: Optimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND ...\n",
      "------------------------------------------------------------\n",
      " Response (2448 characters):\n",
      "----------------------------------------\n",
      "user\n",
      "You are a database performance expert. Optimize the given SQL query.\n",
      "\n",
      "Optimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND region = 'AU'\n",
      "model\n",
      "{\n",
      "  \"original_query\": \"SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND region = 'AU'\",\n",
      "  \"optimized_query\": \"SELECT * FROM subscriptions WHERE event_timestamp >= '2024-06-15' AND\n",
      "... [TRUNCATED - MIDDLE REMOVED] ...\n",
      "\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\n",
      "----------------------------------------\n",
      "\n",
      " Validation:\n",
      "  âœ“ SQL response detected (expected for optimization)\n",
      "  âœ“ Appears to contain optimization suggestions\n",
      "   Response length: 2448 characters\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      " TEST RESULTS SUMMARY (All 5 Tasks)\n",
      "================================================================================\n",
      "\n",
      "1. Data Extraction:\n",
      "  Type: extraction\n",
      "  Response Length: 2423 chars\n",
      "  Status:   Not JSON format\n",
      "\n",
      "2. Schema Inference:\n",
      "  Type: schema_inference\n",
      "  Response Length: 1986 chars\n",
      "  Status:   Not JSON format\n",
      "\n",
      "3. Data Quality Rules:\n",
      "  Type: data_quality\n",
      "  Response Length: 1979 chars\n",
      "  Status:   Not JSON format\n",
      "\n",
      "4. ETL Pipeline Design:\n",
      "  Type: etl_pipeline\n",
      "  Response Length: 2588 chars\n",
      "  Status:   Not JSON format\n",
      "\n",
      "5. SQL Optimization:\n",
      "  Type: sql_optimization\n",
      "  Response Length: 2448 chars\n",
      "  Status:  SQL detected\n",
      "\n",
      "================================================================================\n",
      " TESTING COMPLETE: All 5 task types have been tested\n",
      "   Total tests: 5\n",
      "   Tasks tested: extraction, schema_inference, data_quality, etl_pipeline, sql_optimization\n",
      "================================================================================\n",
      "{'test_number': 5, 'task': '5. SQL Optimization', 'task_type': 'sql_optimization', 'input': \"Optimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND region = 'AU'\", 'response': 'user\\nYou are a database performance expert. Optimize the given SQL query.\\n\\nOptimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = \\'2024-06-15\\' AND region = \\'AU\\'\\nmodel\\n{\\n  \"original_query\": \"SELECT * FROM subscriptions WHERE DATE(event_timestamp) = \\'2024-06-15\\' AND region = \\'AU\\'\",\\n  \"optimized_query\": \"SELECT * FROM subscriptions WHERE event_timestamp >= \\'2024-06-15\\' AND event_timestamp < \\'2024-06-16\\' AND region = \\'AU\\'\",\\n  \"optimizations\": [\\n    \"Replace DATE() function with range comparison\",\\n    \"Add index on (region, event_timestamp)\"\\n  ],\\n  \"expected_improvement\": \"3x faster execution\"\\n}<unused64>model\\n<unused6>extract\\nExtract subscription data for 2024-06-15 and later events in the AU region.\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...\">...', 'response_length': 2448}\n",
      "\n",
      " Results saved to: test_results_20260123_100522.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Enhanced Data Engineering Model Testing Suite\n",
    "# OVERVIEW: Test all 5 data engineering task types sequentially\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def test_data_engineering_model(model, tokenizer, test_input, task_type=\"extraction\"):\n",
    "    \"\"\"Test the fine-tuned model on data engineering tasks\"\"\"\n",
    "    \n",
    "    # System prompts for different tasks\n",
    "    system_prompts = {\n",
    "        \"extraction\": \"Extract structured JSON data from the given text.\",\n",
    "        \"schema_inference\": \"You are a data engineer. Infer database schema from the given data description.\",\n",
    "        \"data_quality\": \"You are a data quality engineer. Generate data quality rules for the given table description.\",\n",
    "        \"etl_pipeline\": \"You are an ETL pipeline architect. Design a data pipeline from the given requirements.\",\n",
    "        \"sql_optimization\": \"You are a database performance expert. Optimize the given SQL query.\"\n",
    "    }\n",
    "    \n",
    "    system_prompt = system_prompts.get(task_type, system_prompts[\"extraction\"])\n",
    "    \n",
    "    # Gemma chat format\n",
    "    formatted_prompt = f\"\"\"<start_of_turn>user\n",
    "{system_prompt}\n",
    "\n",
    "{test_input}<end_of_turn>\n",
    "<start_of_turn>model\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [formatted_prompt],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Generation parameters optimized for structured output\n",
    "    generation_config = {\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 40,\n",
    "        \"do_sample\": False,  # Deterministic for structured data\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generation_config)\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract model response\n",
    "    if \"<start_of_turn>model\" in full_response:\n",
    "        response = full_response.split(\"<start_of_turn>model\")[-1].strip()\n",
    "        response = response.replace(\"<end_of_turn>\", \"\").strip()\n",
    "    else:\n",
    "        response = full_response\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPREHENSIVE DATA ENGINEERING LLM TESTING\")\n",
    "print(\"Testing all 5 task types sequentially\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test cases covering ALL 5 data engineering tasks\n",
    "test_suite = [\n",
    "    {\n",
    "        \"task\": \"1. Data Extraction\",\n",
    "        \"input\": \"Extract subscription usage details:\\nCustomer 10001 used Apple Music on Game Console under the Basic plan costing $16.23 in region AU.\",\n",
    "        \"type\": \"extraction\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"2. Schema Inference\", \n",
    "        \"input\": \"Design a database schema for tracking Netflix subscription usage. Include customer details, subscription info, and usage metrics.\",\n",
    "        \"type\": \"schema_inference\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"3. Data Quality Rules\",\n",
    "        \"input\": \"Generate data quality rules for subscription data with fields: customer_id, service_name, subscription_plan, monthly_price_usd, device_type, region, usage_hours, event_timestamp\",\n",
    "        \"type\": \"data_quality\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"4. ETL Pipeline Design\",\n",
    "        \"input\": \"Design an ETL pipeline to process daily Netflix subscription data from CSV files to a data warehouse for analytics.\",\n",
    "        \"type\": \"etl_pipeline\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"5. SQL Optimization\",\n",
    "        \"input\": \"Optimize this SQL query: SELECT * FROM subscriptions WHERE DATE(event_timestamp) = '2024-06-15' AND region = 'AU'\",\n",
    "        \"type\": \"sql_optimization\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test results storage\n",
    "all_results = []\n",
    "\n",
    "# Test each task type sequentially\n",
    "print(\"\\n STARTING TESTS...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, test_case in enumerate(test_suite, 1):\n",
    "    print(f\"\\n TEST {i}: {test_case['task']}\")\n",
    "    print(f\" Task Type: {test_case['type']}\")\n",
    "    print(f\" Input: {test_case['input'][:100]}...\" if len(test_case['input']) > 100 else f\"ðŸ“¥ Input: {test_case['input']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Run the test\n",
    "    response = test_data_engineering_model(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        test_case['input'],\n",
    "        test_case['type']\n",
    "    )\n",
    "    \n",
    "    # Store result\n",
    "    result = {\n",
    "        \"test_number\": i,\n",
    "        \"task\": test_case['task'],\n",
    "        \"task_type\": test_case['type'],\n",
    "        \"input\": test_case['input'],\n",
    "        \"response\": response,\n",
    "        \"response_length\": len(response)\n",
    "    }\n",
    "    all_results.append(result)\n",
    "    \n",
    "    # Display response\n",
    "    print(f\" Response ({len(response)} characters):\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    \n",
    "    # Show full response (truncate if too long)\n",
    "    if len(response) > 800:\n",
    "        print(response[:400])\n",
    "        print(\"... [TRUNCATED - MIDDLE REMOVED] ...\")\n",
    "        print(response[-400:])\n",
    "    else:\n",
    "        print(response)\n",
    "    \n",
    "    print(f\"{'-'*40}\")\n",
    "    \n",
    "    # Validate based on task type\n",
    "    print(f\"\\n Validation:\")\n",
    "    \n",
    "    # Check if response is JSON for appropriate tasks\n",
    "    if test_case['type'] in ['extraction', 'schema_inference', 'data_quality', 'etl_pipeline']:\n",
    "        try:\n",
    "            # Clean response (remove markdown code blocks if present)\n",
    "            clean_response = response.strip()\n",
    "            if clean_response.startswith(\"```json\"):\n",
    "                clean_response = clean_response[7:]\n",
    "            if clean_response.endswith(\"```\"):\n",
    "                clean_response = clean_response[:-3]\n",
    "            clean_response = clean_response.strip()\n",
    "            \n",
    "            if clean_response.startswith(\"{\") or clean_response.startswith(\"[\"):\n",
    "                parsed = json.loads(clean_response)\n",
    "                print(f\"  âœ“ Valid JSON format\")\n",
    "                print(f\"  âœ“ Contains {len(str(parsed))} characters\")\n",
    "                \n",
    "                # Show keys if it's a dictionary\n",
    "                if isinstance(parsed, dict):\n",
    "                    keys = list(parsed.keys())\n",
    "                    print(f\"  âœ“ Keys in response: {keys[:8]}{'...' if len(keys) > 8 else ''}\")\n",
    "                else:\n",
    "                    print(f\"  âœ“ Response is a JSON array/list\")\n",
    "            else:\n",
    "                print(f\"    Response is not JSON format (doesn't start with {{ or [)\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"   Invalid JSON format: {str(e)}\")\n",
    "    \n",
    "    # Special handling for SQL optimization\n",
    "    elif test_case['type'] == 'sql_optimization':\n",
    "        if 'SELECT' in response.upper() or 'WHERE' in response.upper():\n",
    "            print(f\"  âœ“ SQL response detected (expected for optimization)\")\n",
    "            # Check if it looks like optimized SQL\n",
    "            if 'DATE(' not in response or '>=' in response:\n",
    "                print(f\"  âœ“ Appears to contain optimization suggestions\")\n",
    "        else:\n",
    "            print(f\"    May not be SQL format\")\n",
    "    \n",
    "    print(f\"   Response length: {len(response)} characters\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "\n",
    "# Display summary of all 5 results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" TEST RESULTS SUMMARY (All 5 Tasks)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for result in all_results:\n",
    "    print(f\"\\n{result['task']}:\")\n",
    "    print(f\"  Type: {result['task_type']}\")\n",
    "    print(f\"  Response Length: {result['response_length']} chars\")\n",
    "    \n",
    "    # Quick validation indicator\n",
    "    if result['task_type'] == 'sql_optimization':\n",
    "        if 'SELECT' in result['response'].upper():\n",
    "            print(f\"  Status:  SQL detected\")\n",
    "        else:\n",
    "            print(f\"  Status:   May not be SQL\")\n",
    "    else:\n",
    "        try:\n",
    "            clean_resp = result['response'].strip()\n",
    "            if clean_resp.startswith(\"```json\"):\n",
    "                clean_resp = clean_resp[7:]\n",
    "            if clean_resp.endswith(\"```\"):\n",
    "                clean_resp = clean_resp[:-3]\n",
    "            clean_resp = clean_resp.strip()\n",
    "            \n",
    "            if clean_resp.startswith(\"{\") or clean_resp.startswith(\"[\"):\n",
    "                json.loads(clean_resp)\n",
    "                print(f\"  Status:  Valid JSON\")\n",
    "            else:\n",
    "                print(f\"  Status:   Not JSON format\")\n",
    "        except:\n",
    "            print(f\"  Status:  Invalid JSON\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\" TESTING COMPLETE: All 5 task types have been tested\")\n",
    "print(f\"   Total tests: {len(all_results)}\")\n",
    "print(f\"   Tasks tested: {', '.join([r['task_type'] for r in all_results])}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Optional: Save results to file\n",
    "try:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_filename = f\"test_results_{timestamp}.json\"\n",
    "    \n",
    "    # Prepare results for saving\n",
    "    save_data = []\n",
    "    for result in all_results:\n",
    "        save_data.append({\n",
    "            \"task\": result['task'],\n",
    "            \"task_type\": result['task_type'],\n",
    "            \"input\": result['input'],\n",
    "            \"response\": result['response'],\n",
    "            \"response_length\": result['response_length'],\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "    print(result)\n",
    "    \n",
    "    with open(results_filename, 'w') as f:\n",
    "        json.dump(save_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n Results saved to: {results_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n  Could not save results: {e}\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6438885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1682981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
